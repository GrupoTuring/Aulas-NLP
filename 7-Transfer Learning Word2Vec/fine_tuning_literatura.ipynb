{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_doc(doc):\n",
    "    sents = sent_tokenize(doc)\n",
    "    processed_sents = [word_tokenize(sent) for sent in sents]\n",
    "    return processed_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o primeiro modelo - Guimarães"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'guimaraes'\n",
    "guimaraes_texts = [os.path.join(BASE_DIR, file) for file in os.listdir(BASE_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guimaraes/Primeiras Estórias (completo).txt',\n",
       " 'guimaraes/Noites do Sertão - João Guimarães Rosa.txt',\n",
       " 'guimaraes/Ave, Palavra - João Guimarães Rosa.txt',\n",
       " 'guimaraes/Manuelzão e Miguilim - João Guimarães Rosa.txt',\n",
       " 'guimaraes/No Urubuquaquá, No Pinhém - João Guimarães Rosa.txt',\n",
       " 'guimaraes/1 Guimarães Rosa - Sagarana.txt',\n",
       " 'guimaraes/Tutameia - João Guimarães Rosa.txt',\n",
       " 'guimaraes/Estas Estórias - Joao Guimaraes Rosa.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guimaraes_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for text in guimaraes_texts:\n",
    "    with open(text, \"r\") as f:\n",
    "        t = f.read()\n",
    "        corpus.append(t.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "for doc in corpus:\n",
    "    processed_sents = tokenize_doc(doc)\n",
    "    processed_docs = processed_docs + processed_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(Phrases(processed_docs, min_count=2, threshold=30))\n",
    "gensim_corpus = bigram[processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(min_count=4, size=100, window=4) \n",
    "w2v.build_vocab(gensim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12347534, 22551960)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(gensim_corpus, total_examples=w2v.corpus_count, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('irmã', 0.6933686137199402),\n",
       " ('filha', 0.676548182964325),\n",
       " ('família', 0.6579251885414124),\n",
       " ('noiva', 0.6362385749816895),\n",
       " ('moça', 0.6296038627624512),\n",
       " ('mãe', 0.6248952746391296),\n",
       " ('rapariga', 0.622147798538208),\n",
       " ('Manuela', 0.6203331351280212),\n",
       " ('menina', 0.603524923324585),\n",
       " ('senhora', 0.6034640669822693)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=[\"mulher\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rapaz', 0.5376620292663574),\n",
       " ('sujeito', 0.5371572375297546),\n",
       " ('filho', 0.5266872644424438),\n",
       " ('morto', 0.5226889848709106),\n",
       " ('pobre', 0.5208336710929871),\n",
       " ('rico', 0.5175313353538513),\n",
       " ('vaqueiro', 0.4968743622303009),\n",
       " ('companheiro', 0.4865562915802002),\n",
       " ('pressentimento', 0.47348666191101074),\n",
       " ('rapazinho', 0.4694969654083252)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar(positive=[\"homem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.wvsave_word2vec_format(\"word2vec_guimaraes.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning Clarice Lispector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR_FINE_TUNING = 'clarice'\n",
    "clarice_texts = [os.path.join(BASE_DIR_FINE_TUNING, file) for file in os.listdir(BASE_DIR_FINE_TUNING)]\n",
    "corpus_ft = []\n",
    "for text in clarice_texts:\n",
    "    with open(text, \"r\") as f:\n",
    "        t = f.read()\n",
    "        corpus_ft.append(t.replace(\"\\n\", \"\"))\n",
    "\n",
    "processed_docs_ft = []\n",
    "for doc in corpus_ft:\n",
    "    processed_sents = tokenize_doc(doc)\n",
    "    processed_docs_ft = processed_docs_ft + processed_sents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_ft = Phraser(Phrases(processed_docs_ft, min_count=2, threshold=30))\n",
    "gensim_corpus_ft = bigram_ft[processed_docs_ft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7525147, 12756390)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft = Word2Vec(size=100,min_count=4, window=4)\n",
    "model_ft.build_vocab(gensim_corpus_ft)\n",
    "model_ft.intersect_word2vec_format(\"word2vec_guimaraes.txt\", lockf=1.0)\n",
    "model_ft.train(processed_docs_ft, total_examples=model_ft.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('velho', 0.49869149923324585),\n",
       " ('cão', 0.4902336299419403),\n",
       " ('rapaz', 0.4862063527107239),\n",
       " ('quati', 0.4799765944480896),\n",
       " ('morto', 0.4369499683380127),\n",
       " ('gato', 0.42170870304107666),\n",
       " ('dono', 0.419739305973053),\n",
       " ('moço', 0.3973882794380188),\n",
       " ('bicho', 0.39719587564468384),\n",
       " ('animal', 0.39257094264030457)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.wv.most_similar(positive=[\"homem\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets",
   "language": "python",
   "name": "tweets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
